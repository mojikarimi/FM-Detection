{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Face Mask Detection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe4beadc91ba997c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Masks play an important role in protecting people's health from respiratory diseases, as they are one of the few precautions available for COVID-19 in the absence of immunization. Using this NoteBook, a model can be created to identify people who use masks, do not use them, or use inappropriate masks.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6fb745b02722e69"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Table of Contents:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83d108ae18d56204"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. [Introduction](#Introduction)\n",
    "2. [Algorithm used](#Algorithm-used)\n",
    "3. [Import libraries](#Import-libraries)\n",
    "4. [Call data set](#call-data-set)\n",
    "5. [Read all photos](#read-all-photos)\n",
    "6. [Specify the output](#specify-the-output)\n",
    "7. [Normalization](#normalization)\n",
    "8. [Training and test data](#training-and-test-data)\n",
    "9. [create Model](#create-model)\n",
    "10. [compile model](#compile-model)\n",
    "11. [Model testing](#model-testing)\n",
    "12. [Save Model](#save-model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8be534d1f4b9aba0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Introduction:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94c1c09fa2ac56a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The purpose of this notebook is to build a face mask recognition model and how to implement this model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "810c46769cff166a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Algorithm used:\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17da5993511a8bd6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "`CNN(Convolutional Neural Network)` algorithm is used in this code, which is one of the most powerful deep learning algorithms.\n",
    "\n",
    "A Convolutional Neural Network (CNN), also known as ConvNet, is a specialized type of deep learning algorithm mainly designed for tasks that necessitate object recognition, including image classification, detection, and segmentation. CNNs are employed in a variety of practical scenarios, such as autonomous vehicles, security camera systems, and others."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf2c985b92d62726"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11062a983343705e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten,Dropout,MaxPool2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow\n",
    "import pickle"
   ],
   "metadata": {
    "id": "b900d523-6ccf-4e72-9ad8-e577110390ce"
   },
   "id": "b900d523-6ccf-4e72-9ad8-e577110390ce",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Call data set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c2f32b670c6b49d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Hint:** This data set is called in colab, you must change the path as below.\n",
    "\n",
    "path_with_mask: `../DataSets/with_mask`\n",
    "path_without_mask: `../DataSets/without_mask`\n",
    "\n",
    "To read the datasets, we used `os.listdir`, which is one of Python's internal methods and libraries."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdc451af8e1df736"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "img_path_with_mask=os.listdir('/content/drive/MyDrive/with_mask')\n",
    "img_path_without_mask=os.listdir('/content/drive/MyDrive/without_mask')"
   ],
   "metadata": {
    "id": "975a2493-eee3-4c5d-aedf-0b3bd0c20709"
   },
   "id": "975a2493-eee3-4c5d-aedf-0b3bd0c20709",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beb0096b-8089-4303-87d7-db2c4e5971c6",
   "metadata": {
    "id": "beb0096b-8089-4303-87d7-db2c4e5971c6"
   },
   "outputs": [],
   "source": [
    "# Set weight & height (w,h)\n",
    "w,h=100,100"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Read all photos"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3ab8f7c448f49b0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have read the photos using `cv2.imread` and then add them all to a list to have a list of all photos array.\n",
    "\n",
    "All photos must be converted to the same size to be used in the algorithm, and for this we use `cv2.resize`.\n",
    "\n",
    "**Hint:** This data set is called in colab, you must change the path as below.\n",
    "\n",
    "path_with_mask: `../DataSets/with_mask`\n",
    "path_without_mask: `../DataSets/without_mask`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2809fe05a2b6240c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47978b93-f1b9-4efb-b3bf-087d142ab15b",
   "metadata": {
    "id": "47978b93-f1b9-4efb-b3bf-087d142ab15b"
   },
   "outputs": [],
   "source": [
    "mask=[]\n",
    "for i in img_path_with_mask:\n",
    "    img=cv2.imread('/content/drive/MyDrive/with_mask/'+i)\n",
    "    img=cv2.resize(img,(w,h))\n",
    "    mask.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d28fa6d9-050a-495f-9f81-3ade15045a66",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d28fa6d9-050a-495f-9f81-3ade15045a66",
    "outputId": "3740bb60-d65a-47e6-82c3-8d9898d37ed2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2892, 100, 100, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask=np.array(mask)\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "900f6985-16a1-4ad4-8f3d-ea9d049498be",
   "metadata": {
    "id": "900f6985-16a1-4ad4-8f3d-ea9d049498be"
   },
   "outputs": [],
   "source": [
    "nomask=[]\n",
    "for i in img_path_without_mask:\n",
    "  img=cv2.imread('/content/drive/MyDrive/without_mask5/'+i)\n",
    "  img=cv2.resize(img,(w,h))\n",
    "  nomask.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "546de891-2e43-4eba-8257-735477dd019f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "546de891-2e43-4eba-8257-735477dd019f",
    "outputId": "f9fcd92d-aa08-4fa6-d00e-d5968096b364"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3476, 100, 100, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomask=np.array(nomask)\n",
    "nomask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Specify the output"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ecc3889e3dca9d31"
  },
  {
   "cell_type": "markdown",
   "source": [
    "`1` for people who wore masks and `0` for those who did not\n",
    "For this, we used two methods `np.ones` and `np.zeros`, and then we combined the two presentations with the `np.concatenate` method and turned them into categorical using the `to_categorical` method."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ec621f4eeb641c5"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73e421ad-a191-452b-9583-e7cf47c715c0",
   "metadata": {
    "id": "73e421ad-a191-452b-9583-e7cf47c715c0"
   },
   "outputs": [],
   "source": [
    "result_nomask=np.zeros(nomask.shape[0])\n",
    "result_mask=np.ones(mask.shape[0])\n",
    "result=np.concatenate((result_nomask,result_mask))\n",
    "result_cat = to_categorical(result, num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Normalization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ef84e7bee5ec13a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this, we used the following formula:\n",
    "\n",
    "$$ \\frac{array-min(array)}{max(array) - min(array)} $$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b72c03a45e367d3"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b926c57-3f20-4c6c-a912-92565749a2dd",
   "metadata": {
    "id": "0b926c57-3f20-4c6c-a912-92565749a2dd"
   },
   "outputs": [],
   "source": [
    "mask=mask.reshape(mask.shape[0], w,h, 3)\n",
    "nomask=nomask.reshape(nomask.shape[0], w,h, 3)\n",
    "mask=(mask-mask.min())/(mask.max()-mask.min())\n",
    "nomask=(nomask-nomask.min())/(nomask.max()-nomask.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed322ec2-5aa8-480a-b9d4-f7fc10521692",
   "metadata": {
    "id": "ed322ec2-5aa8-480a-b9d4-f7fc10521692"
   },
   "outputs": [],
   "source": [
    "# mix 2 Array\n",
    "input_dl=np.concatenate((nomask,mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training and test data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41bb0b3986a3cc0d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this, we used the `train_test_split` method, with the use of this method, the data is divided for us in a shuffled manner, and we can use the test data provided by us to test our model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c80f1d5b1779d176"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2df4856d-3bce-4218-8425-04139eb5794b",
   "metadata": {
    "id": "2df4856d-3bce-4218-8425-04139eb5794b"
   },
   "outputs": [],
   "source": [
    "# creat test & train data\n",
    "x_train, x_test, y_train, y_test=train_test_split(input_dl, result_cat, test_size=.2, random_state=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### create Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac7a29994f2b81a4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We used `Sequential` to build the `model` and we used the `Conv2D` method to add c`onvolution layers` and set the required values such as the `kernel size`, etc. and we used the `MaxPool2D` method for the `pool layers` and the `Dropout` method for the layer We used `Dropout` and we used `Dense` for `fully connected layers` and we used two activation functions `relu` and `sigmoid` to activate the functions."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42e12b4888ce5734"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fac8825-263e-4961-bc09-f22840bdac34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fac8825-263e-4961-bc09-f22840bdac34",
    "outputId": "a782c7e5-5694-451b-f49f-85b6d68e7d97"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(25, kernel_size=5,strides=(1,1),padding='same',\n",
    "                 activation='relu', input_shape=(100,100, 3)))\n",
    "model.add(Conv2D(50,strides=(1,1),padding='same', kernel_size=5,\n",
    "                 activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(3,3)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(75,strides=(1,1),padding='same', kernel_size=3,\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(1,1)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(125,strides=(1,1),padding='same', kernel_size=3,\n",
    "                 activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(1, 1)))\n",
    "model.add(Conv2D(175,strides=(1,1),padding='same', kernel_size=3,\n",
    "                 activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(1, 1)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(125, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### compile model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be4b7fa3cd878b10"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4048315-e4a9-48c8-be3f-c9fbf9c21dee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f4048315-e4a9-48c8-be3f-c9fbf9c21dee",
    "outputId": "124c3020-1200-4db8-e1ab-2ef163824ffd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m51/51\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m917s\u001B[0m 18s/step - accuracy: 0.6650 - loss: 0.6001 - val_accuracy: 0.9584 - val_loss: 0.1255\n",
      "Epoch 2/20\n",
      "\u001B[1m51/51\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m919s\u001B[0m 18s/step - accuracy: 0.9630 - loss: 0.1285 - val_accuracy: 0.9694 - val_loss: 0.0835\n",
      "Epoch 3/20\n",
      "\u001B[1m51/51\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m940s\u001B[0m 18s/step - accuracy: 0.9717 - loss: 0.1021 - val_accuracy: 0.9796 - val_loss: 0.0797\n",
      "Epoch 4/20\n",
      "\u001B[1m51/51\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m930s\u001B[0m 18s/step - accuracy: 0.9722 - loss: 0.0996 - val_accuracy: 0.9733 - val_loss: 0.0877\n",
      "Epoch 5/20\n",
      "\u001B[1m51/51\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m978s\u001B[0m 18s/step - accuracy: 0.9792 - loss: 0.0844 - val_accuracy: 0.9851 - val_loss: 0.0487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fb22248ba60>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "callback = tensorflow.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0.01,\n",
    "    patience=2\n",
    ")\n",
    "model.fit(x=x_train, y=y_train,\n",
    "          batch_size=100, epochs=20,\n",
    "         validation_data=(x_test, y_test)\n",
    "          ,callbacks=[callback]\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model testing\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e8534ce79ea1534"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We used `evaluate` method and `test data` to test the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59059f6b68da6cca"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "k79peewUvndw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k79peewUvndw",
    "outputId": "9de68d32-b92a-407f-c812-a3927a4a2e15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m54s\u001B[0m 1s/step - accuracy: 0.9869 - loss: 0.0465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04865759238600731, 0.9850863218307495]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37c1e21daae35ffa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Getting the output from the model using the `pickle.dump` method.\n",
    "\n",
    "**Hint:** In order for the code to work fully with the `Django` site, you must place the created model in the directory of the `Django` project (`DL_Detection`) in the `model` directory.\n",
    "\n",
    "If the model directory was not created, create it in `BASE_DIR`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c903cba422f9477"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3GM_DWwCzbW",
   "metadata": {
    "id": "f3GM_DWwCzbW"
   },
   "outputs": [],
   "source": [
    "pickle.dump(model, open('model_9850_0486.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d907196-b525-42de-8fe0-fae110a30641",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
